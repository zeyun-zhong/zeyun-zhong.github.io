<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zeyun-zhong.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zeyun-zhong.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-23T09:44:21+00:00</updated><id>https://zeyun-zhong.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Introducing NestConfig</title><link href="https://zeyun-zhong.github.io/blog/2024/NestConfig/" rel="alternate" type="text/html" title="Introducing NestConfig"/><published>2024-03-22T00:00:00+00:00</published><updated>2024-03-22T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2024/NestConfig</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2024/NestConfig/"><![CDATA[<h2 id="tldr">TL;DR</h2> <p>NestConfig is a Python library designed to simplify configuration management in applications, leveraging the power of dataclasses. It enhances your development experience by offering:</p> <ul> <li><strong>Type-Safe Configuration Updates</strong></li> <li><strong>Command-Line Integration</strong></li> <li><strong>Export Configurations to YAML</strong></li> <li><strong>Auto-Completion Support</strong></li> </ul> <h2 id="introduction">Introduction</h2> <p>Configuring Python applications can often be a hassle, especially when dealing with complex hierarchies or external configuration files. NestConfig aims to simplify this process, providing a robust and intuitive approach to handling configurations.</p> <h2 id="how-nestconfig-simplifies-configuration-management">How NestConfig Simplifies Configuration Management</h2> <p>NestConfig builds upon the simplicity of dataclasses and enhances them with powerful merging capabilities. Let’s dive into two of its core features: <code class="language-plaintext highlighter-rouge">merge_updates</code> and <code class="language-plaintext highlighter-rouge">merge_opts</code>.</p> <h3 id="the-merge_updates-method">The <code class="language-plaintext highlighter-rouge">merge_updates</code> Method</h3> <p>The <code class="language-plaintext highlighter-rouge">merge_updates</code> method is a key feature of NestConfig that facilitates the merging of configurations from external sources. Consider a scenario where you have a YAML file with configuration parameters you want to apply to your application dynamically. Here’s an example <code class="language-plaintext highlighter-rouge">config.yaml</code> file content:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">LEARNING_RATE</span><span class="pi">:</span> <span class="m">0.001</span>
<span class="na">BATCH_SIZE</span><span class="pi">:</span> <span class="m">64</span>
<span class="na">MODEL</span><span class="pi">:</span>
  <span class="na">N_LAYER</span><span class="pi">:</span> <span class="m">6</span>
</code></pre></div></div> <p>This file defines several configuration parameters, including a nested parameter under <code class="language-plaintext highlighter-rouge">MODEL</code>. To incorporate these updates into your application, you would typically load the YAML file and then call <code class="language-plaintext highlighter-rouge">merge_updates</code> on your configuration object:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">nestconfig</span> <span class="kn">import</span> <span class="n">NestConfig</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">import</span> <span class="n">yaml</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">:</span>
    <span class="n">N_LAYER</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Config</span><span class="p">(</span><span class="n">NestConfig</span><span class="p">):</span>
    <span class="n">LEARNING_RATE</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">MODEL</span><span class="p">:</span> <span class="n">ModelConfig</span> <span class="o">=</span> <span class="nf">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">ModelConfig</span><span class="p">)</span>

<span class="c1"># Load configuration updates from an external YAML file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">config.yaml</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">config_updates</span> <span class="o">=</span> <span class="n">yaml</span><span class="p">.</span><span class="nf">safe_load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

<span class="c1"># Create a Config instance and merge updates
</span><span class="n">config</span> <span class="o">=</span> <span class="nc">Config</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="nf">merge_updates</span><span class="p">(</span><span class="n">config_updates</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">LEARNING_RATE</span><span class="p">)</span>  <span class="c1"># Output: 0.001
</span><span class="nf">print</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">BATCH_SIZE</span><span class="p">)</span>     <span class="c1"># Output: 64
</span><span class="nf">print</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">MODEL</span><span class="p">.</span><span class="n">N_LAYER</span><span class="p">)</span>  <span class="c1"># Output: 6
</span></code></pre></div></div> <p>By executing this script, NestConfig reads the <code class="language-plaintext highlighter-rouge">config.yaml</code> file, loads the settings, and updates the config object. The output confirms that the default value of <code class="language-plaintext highlighter-rouge">N_LAYER</code> is overridden by the value specified in the YAML file.</p> <h4 id="merge_yaml"><code class="language-plaintext highlighter-rouge">merge_yaml</code></h4> <p>For convenience, NestConfig also provides a method named <code class="language-plaintext highlighter-rouge">merge_yaml</code> which directly loads and merges the YAML configuration file:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">config</span> <span class="o">=</span> <span class="nc">Config</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="nf">merge_yaml</span><span class="p">(</span><span class="sh">'</span><span class="s">config.yaml</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">MODEL</span><span class="p">.</span><span class="n">N_LAYER</span><span class="p">)</span>  <span class="c1"># Output: 6
</span></code></pre></div></div> <h3 id="the-merge_opts-method">The <code class="language-plaintext highlighter-rouge">merge_opts</code> Method</h3> <p><code class="language-plaintext highlighter-rouge">merge_opts</code> is designed to work seamlessly with command-line arguments, enabling easy integration with tools like argparse. This method merges a list of options directly into the configuration object.</p> <p>Here’s a simple demonstration of how to use <code class="language-plaintext highlighter-rouge">merge_opts</code> with <code class="language-plaintext highlighter-rouge">argparse</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">nestconfig</span> <span class="kn">import</span> <span class="n">NestConfig</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">import</span> <span class="n">argparse</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">:</span>
    <span class="n">N_LAYER</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Config</span><span class="p">(</span><span class="n">NestConfig</span><span class="p">):</span>
    <span class="n">LEARNING_RATE</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">MODEL</span><span class="p">:</span> <span class="n">ModelConfig</span> <span class="o">=</span> <span class="nf">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">ModelConfig</span><span class="p">)</span>

<span class="c1"># Set up argparse
</span><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="nc">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">'</span><span class="s">Test merge_opts function.</span><span class="sh">'</span><span class="p">)</span>
<span class="n">parser</span><span class="p">.</span><span class="nf">add_argument</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">--opts</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">help</span><span class="o">=</span><span class="sh">"</span><span class="s">See the Config definition for all options</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">MODEL.N_LAYER</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">12</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="p">.</span><span class="n">REMAINDER</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="nf">parse_args</span><span class="p">()</span>

<span class="c1"># Create a Config instance and merge command-line options
</span><span class="n">config</span> <span class="o">=</span> <span class="nc">Config</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="nf">merge_opts</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">opts</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">MODEL</span><span class="p">.</span><span class="n">N_LAYER</span><span class="p">)</span>  <span class="c1"># 12
</span></code></pre></div></div> <p>In this code snippet, we set up argparse to accept command-line options. We then pass these options as a list to the merge_opts function, which merges them into our Config object. The merge_opts method ensures that the command-line options take precedence, updating the configuration instance’s values accordingly.</p> <h3 id="saving-configurations-with-to_yaml">Saving Configurations with <code class="language-plaintext highlighter-rouge">to_yaml</code></h3> <p>You can also export current configurations for reuse or inspection. NestConfig addresses this by providing a <code class="language-plaintext highlighter-rouge">to_yaml</code> method, enabling you to serialize and save your configuration objects back to YAML format.</p> <p>To demonstrate the <code class="language-plaintext highlighter-rouge">to_yaml</code> functionality, let’s consider an example where we modify our application’s configuration via command-line arguments and then save the resulting configuration to a YAML file:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">nestconfig</span> <span class="kn">import</span> <span class="n">NestConfig</span>
<span class="kn">from</span> <span class="n">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">import</span> <span class="n">argparse</span>
<span class="kn">import</span> <span class="n">yaml</span>  <span class="c1"># Ensure you have PyYAML installed
</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">:</span>
    <span class="n">N_LAYER</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">Config</span><span class="p">(</span><span class="n">NestConfig</span><span class="p">):</span>
    <span class="n">LEARNING_RATE</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span>
    <span class="n">BATCH_SIZE</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span>
    <span class="n">MODEL</span><span class="p">:</span> <span class="n">ModelConfig</span> <span class="o">=</span> <span class="nf">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">ModelConfig</span><span class="p">)</span>

<span class="c1"># Set up argparse
</span><span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="p">.</span><span class="nc">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="sh">'</span><span class="s">Test merge_opts function.</span><span class="sh">'</span><span class="p">)</span>
<span class="n">parser</span><span class="p">.</span><span class="nf">add_argument</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">--opts</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">help</span><span class="o">=</span><span class="sh">"</span><span class="s">See the Config definition for all options</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">default</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">MODEL.N_LAYER</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">12</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">nargs</span><span class="o">=</span><span class="n">argparse</span><span class="p">.</span><span class="n">REMAINDER</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="p">.</span><span class="nf">parse_args</span><span class="p">()</span>

<span class="c1"># Create a Config instance and merge command-line options
</span><span class="n">config</span> <span class="o">=</span> <span class="nc">Config</span><span class="p">()</span>
<span class="n">config</span><span class="p">.</span><span class="nf">merge_opts</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">opts</span><span class="p">)</span>

<span class="c1"># Save the current Config as a YAML file to inspect later on
</span><span class="n">config</span><span class="p">.</span><span class="nf">to_yaml</span><span class="p">(</span><span class="sh">"</span><span class="s">config_new.yaml</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>In this example, after merging the command-line options into our <code class="language-plaintext highlighter-rouge">Config</code> object, we call <code class="language-plaintext highlighter-rouge">config.to_yaml("config_new.yaml")</code> to save the current state of the configuration to a file named <code class="language-plaintext highlighter-rouge">config_new.yaml</code>. This YAML file can then be used as a configuration template for future runs or shared among team members to ensure consistent settings.</p> <h3 id="advantages-over-argparse-and-fvcore">Advantages Over argparse and fvcore</h3> <p>While argparse is a versatile module for command-line argument parsing, NestConfig extends its functionality within the application’s configuration context. With NestConfig, you can:</p> <ul> <li>Maintain Type Safety: NestConfig respects the types defined in your dataclasses, ensuring that merged values adhere to the expected types, reducing runtime errors.</li> <li>Support Nested Configurations: Unlike argparse, which typically handles flat argument structures, NestConfig can elegantly manage complex, nested configurations.</li> <li>Integrate with External Configuration Files: NestConfig can easily merge configurations from files in formats like YAML, making it versatile for projects that require external configuration files.</li> <li>Seamless argparse Integration: merge_opts can directly handle the output of argparse, allowing you to merge command-line arguments into your application’s configuration object with ease.</li> <li>Comparison to fvcore: While fvcore provides a CfgNode object for managing hierarchies of configurations, NestConfig offers the added benefit of Pythonic type safety and autocomplete features due to its dataclass foundation.</li> </ul> <h2 id="install-via-pip">Install via pip</h2> <p>Code in this blog can be found in the <a href="https://github.com/zeyun-zhong/NestConfig">Project Page</a>. To install NestConfig, simply use pip:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>nestconfig
</code></pre></div></div>]]></content><author><name></name></author><summary type="html"><![CDATA[TL;DR NestConfig is a Python library designed to simplify configuration management in applications, leveraging the power of dataclasses. It enhances your development experience by offering:]]></summary></entry><entry><title type="html">Understanding the Gumbel-Softmax Trick</title><link href="https://zeyun-zhong.github.io/blog/2023/Understanding-the-Gumbel-Softmax-Trick/" rel="alternate" type="text/html" title="Understanding the Gumbel-Softmax Trick"/><published>2023-12-04T00:00:00+00:00</published><updated>2023-12-04T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2023/Understanding-the-Gumbel-Softmax-Trick</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2023/Understanding-the-Gumbel-Softmax-Trick/"><![CDATA[<p>Deep learning models often face challenges when dealing with categorical data, especially in tasks that require differentiable sampling. The Gumbel-Softmax distribution emerges as a solution, blending discrete choice modeling with gradient-based optimization. In this blog, we explore the Gumbel-Softmax distribution, its mechanism, applications, and advantages over traditional softmax in certain scenarios.</p> <h2 id="what-is-gumbel-softmax">What is Gumbel-Softmax?</h2> <p>Gumbel-Softmax is a technique in deep learning that enables differentiable sampling from a categorical distribution, useful in scenarios involving discrete data generation or classification.</p> <h3 id="background">Background</h3> <p>In machine learning models, particularly classification tasks, we deal with categorical distributions. A categorical distribution is a discrete probability distribution that describes the possible results of a random variable that can take on one of \(K\) possible categories, with the probability of each category separately specified. However, traditional sampling from these distributions is non-differentiable, posing challenges for gradient-based learning methods. Gumbel-Softmax provides a solution for differentiable sampling.</p> <h2 id="how-gumbel-softmax-works">How Gumbel-Softmax Works</h2> <p><strong>Introduction of Gumbel Noise</strong>: Add a sample from Gumbel(0, 1) to the log probabilities of categories.</p> \[\text{score}_k = \log(p_k) + G_k\] <p><strong>Application of Softmax Function</strong>: Apply softmax to these scores with a temperature parameter (\(\tau\)) controlling the output’s ‘softness’. When \(\tau\) is close to 0, the softmax function approximates a categorical sample (hard selection). When \(\tau\) is high, the choices become softer, allowing for a smoother gradient.</p> \[y_k = \frac{\exp((\log(p_k) + G_k) / \tau)}{\sum_{i=1}^{K} \exp((\log(p_i) + G_i) / \tau)}\] <p><strong>Output</strong>: The result is a vector approximating a one-hot encoded vector but is differentiable with respect to model parameters.</p> <h2 id="gumbel-softmax-vs-regular-softmax">Gumbel-Softmax vs. Regular Softmax</h2> <p>While softmax is common in classification models, it’s limited in scenarios requiring differentiable sampling. Gumbel-Softmax maintains differentiability due to the incorporation of the Gumbel noise, unlike regular softmax.</p> <h2 id="why-gumbel-noise-can-we-use-gaussian-noise-instead">Why Gumbel Noise? Can We use Gaussian Noise instead?</h2> <p>The Gumbel distribution arises naturally in the context of extreme value theory, particularly in modeling the distribution of the maximum (or minimum) of a set of samples from various distributions. In the case of Gumbel-Softmax, it is used to transform the categorical logits into a sample from the categorical distribution. Gaussian noise, while offering differentiability, lacks the direct mapping to categorical sampling provided by Gumbel noise.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Deep learning models often face challenges when dealing with categorical data, especially in tasks that require differentiable sampling. The Gumbel-Softmax distribution emerges as a solution, blending discrete choice modeling with gradient-based optimization. In this blog, we explore the Gumbel-Softmax distribution, its mechanism, applications, and advantages over traditional softmax in certain scenarios.]]></summary></entry><entry><title type="html">Why is the Denominator of Sample Variance n-1?</title><link href="https://zeyun-zhong.github.io/blog/2021/sample_variance/" rel="alternate" type="text/html" title="Why is the Denominator of Sample Variance n-1?"/><published>2021-10-06T00:00:00+00:00</published><updated>2021-10-06T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2021/sample_variance</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2021/sample_variance/"><![CDATA[<h2 id="mathematical-expectation">Mathematical Expectation</h2> <p>If $f(x)$ is the <a href="https://en.wikipedia.org/wiki/Probability_mass_function">probability mass function</a> (p.m.f.) of the discrete random variable $X$ with support $S$, and if the summation:</p> \[\sum_{x\in S} u(x)f(x)\] <p>exists (less than $\infty$), then the resulting sum is called the <strong>mathematical expectation</strong>, or the expected value of the function $u(X)$, where $x$ denotes individual sample point. The expectation of the function $u(X)$ is denoted as $E[u(X)]$:</p> \[E[u(X)] = \sum_{x\in S} u(x)f(x).\] <h2 id="population-mean-and-variance">Population Mean and Variance</h2> <p>If we consider one particular function: $u(X) = X$, then the expectation of $u(X)$:</p> \[E[u(X)] = E[X] = \sum_{x\in S} xf(x),\] <p>is called the <strong>expected value</strong> of $X$, denoted as $E[X]$. Or, it is called the <strong>mean</strong> of $X$, denoted as $\mu$.</p> <p>Now, let’s consider another function: $u(X) = (X-\mu)^2$, the corresponding expectation:</p> \[E[u(X)] = E[(X-\mu)^2] = \sum_{x\in S}(x-\mu)^2f(x),\] <p>is called the <strong>variance</strong> of $X$, denoted as $\mathrm{Var}(X)$ or $\sigma^2$.</p> <h2 id="sample-mean-and-variance">Sample Mean and Variance</h2> <p>If the population is too large and we still want to decribe the population using mean and variance, then it would be useful to select a sample and calculate the sample mean and sample variance.</p> <p>The <strong>sample mean</strong> is simply the average of the $n$ data points $x_1$, $x_2$, …, $x_n$:</p> \[\bar{x} = \frac{x_1+x_2+...+x_n}{n} = \frac{1}{n}\sum_{i=1}^n x_i.\] <p>The <strong>sample variance</strong> summaries the “spread” or “variation” of the data:</p> \[\begin{aligned} s^2 &amp;= \frac{(x_1-\bar{x})^2+(x_2-\bar{x})^2+ ... +(x_n-\bar{x})^2}{n-1} \\ &amp;= \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2. \end{aligned}\] <h2 id="important-properties">Important Properties</h2> <p>Note that the denominator of the sample variance is $n-1$. Why is that? Before we start to analyse that, we first look at some important properties of expectation. The proof will be given in the next section.</p> <p><strong>Property 1</strong>:</p> <p>if c is a constant, then $E[c] = c$ and $E[cu(X)] = cE[u(X)]$.</p> <p><strong>Property 2</strong>:</p> <p>$E[u_1(X) + u_2(X)] = E[u_1(X)] + E[u_2(X)]$.</p> <p><strong>Property 3</strong>:</p> <p>if $X_1$, $X_2$, …, $X_n$ are $n$ independent random variables with means $\mu_1$, $\mu_2$, …, $\mu_n$ and variances $\sigma_1^2$, $\sigma_2^2$, …, $\sigma_n^2$. Then, the mean and variance of the linear combination $Y = \sum_{i=1}^{n}a_iX_i$ ($a_i$ are real constants) are:</p> \[\begin{aligned} \mu_Y &amp;= \sum_{i=1}^n a_i\mu_i \\ \sigma_Y^2 &amp;= \sum_{i=1}^n a_i^2 \sigma_i^2. \end{aligned}\] <h2 id="proof">Proof</h2> <p>Let’s do some proof in this section.</p> <p><strong>Property 1</strong>:</p> \[\begin{aligned} E[c] &amp;= \sum_{x\in S}cf(x) = c\sum_{x\in S}f(x) = c \times 1 = c \\ E[cu(X)] &amp;= \sum_{x\in S}cu(X)f(x) = c\sum_{x\in S}u(X)f(x) = cE[u(X)]. \end{aligned}\] <p><strong>Property 2</strong>:</p> \[\begin{aligned} E[u_1(X) + u_2(X)] &amp;= \sum_{x\in S} (u_1(X) + u_2(X))f(x) \\ &amp;= \sum_{x\in S} u_1(X)f(x) + \sum_{x\in S} u_2(X)f(x) \\ &amp;= E[u_1(X)] + E[u_2(X)] \end{aligned}\] <p><strong>Property 3</strong>:</p> \[\begin{aligned} \mu_Y &amp;= E[Y] = E[\sum_{i=1}^n a_iX_i] = \sum_{i=1}^n E[a_iX_i] \\ &amp;= \sum_{i=1}^n a_i E[X_i] = \sum_{i=1}^n a_i\mu_i \end{aligned}\] \[\begin{aligned} \sigma_Y^2 &amp;= E[(Y-\mu_Y)^2] \\ &amp;= E[(\sum_{i=1}^n a_iX_i - \sum_{i=1}^n a_i\mu_i)^2] \\ &amp;= E[(\sum_{i=1}^na_i(X_i-\mu_i))^2] \\ &amp;= E[(\sum_{i=1}^na_i(X_i-\mu_i))\cdot (\sum_{j=1}^na_j(X_j-\mu_j))] \\ &amp;= E[\sum_{i=1}^n\sum_{j=1}^n a_ia_j(X_i-\mu_i)(X_j-\mu_j)] \\ &amp;= \sum_{i=1}^n\sum_{j=1}^n a_ia_j E[(X_i-\mu_i)(X_j-\mu_j)]. \end{aligned}\] <p>Since $X_1$, $X_2$, …, $X_n$ are independent random variables, the <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">correlation</a> between two arbitrary variables $X_i$ and $X_j$ with $i\neq j$ is zero. This leads us to:</p> \[\sigma_Y^2 = \sum_{i=1}^n a_i^2 E[(X_i-\mu_i)^2] = \sum_{i=1}^n a_i^2 \sigma_i^2.\] <h2 id="why-is-the-denominator-of-sample-variance-n-1">Why is the Denominator of Sample Variance n-1?</h2> <p>If we take the number of data points $n$ as the denominator of the sample variance, we will see that this sample variance is a biased estimator of the population variance:</p> \[\begin{aligned} s_n^2 &amp;= E[\frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2] \\ &amp;= E[\frac{1}{n}\sum_{i=1}^n[(x_i-\mu)-(\bar{x}-\mu)]^2] \\ &amp;= E[\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2-2(x_i-\mu)\underbrace{(\bar{x}-\mu)}_{const.}+\underbrace{(\bar{x}-\mu)^2}_{const.}] \\ &amp;= E[\frac{1}{n}\sum_{i=1}^n(x_i-\mu)^2 - \frac{2(\bar{x}-\mu)}{n}\underbrace{\sum_{i=1}^n(x_i}_{n\cdot\bar{x}}-\mu) + (\bar{x}-\mu)^2] \\ &amp;= E[(X-\mu)^2]- E[2(\bar{x}-\mu)(\bar{x}-\mu)] + E[(\bar{x}-\mu)^2]]\\ &amp;= E[(X-\mu)^2] -E[(\bar{x}-\mu)^2] \\ &amp;= \sigma^2 - \mathrm{Var}(\bar{x}) \\ \end{aligned}\] <p>The bias is therefore $\mathrm{Var}(\bar{x})$, i.e. variance of the sample mean. According to the Property 3, this term can be calculated by:</p> \[\begin{aligned} \mathrm{Var}(\bar{x}) &amp;= \mathrm{Var}(\frac{1}{n}\sum_{i=1}^nx_i) = \mathrm{Var}(\sum_{i=1}^n \frac{1}{n}x_i) \\ &amp;= \sum_{i=1}^n \frac{1}{n^2}\mathrm{Var}(x_i) = \frac{1}{n^2}\sum_{i=1}^n\mathrm{Var}(x_i). \end{aligned}\] <p>Since $x_1$, $x_2$, …, $x_n$ are a random sample from a distribution with variance $\sigma^2$, it follows that for each $i = 1, 2, …, n$: $\mathrm{Var}(x_i)=\sigma^2$. Thus, the variance of the sample mean can be further transformed to:</p> \[\mathrm{Var}(\bar{x}) = \frac{1}{n}\sigma^2.\] <p>Now, we know that the uncorrected sample variance is $s_n^2 = \frac{n-1}{n}\sigma^2$. Thus, the corrected one would be:</p> \[\begin{aligned} s^2 &amp;= \frac{n}{n-1}s_n^2 = \frac{n}{n-1}\cdot \frac{1}{n}\sum_{i=1}^n(x_i-\bar{x})^2 \\ &amp;= \frac{1}{n-1}\sum_{i=1}^n(x_i-\bar{x})^2. \end{aligned}\] <h2 id="reference">Reference</h2> <ul> <li><a href="https://en.wikipedia.org/wiki/Bessel%27s_correction">Bessel Correction Wiki</a></li> <li><a href="https://online.stat.psu.edu/stat414/lesson/8/8.5">PennState Statistics Lecture Sample Means and Variance</a></li> <li><a href="https://online.stat.psu.edu/stat414/lesson/24/24.4">PennState Statistics Lecture Mean and Variance of Sample Mean</a></li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Mathematical Expectation If $f(x)$ is the probability mass function (p.m.f.) of the discrete random variable $X$ with support $S$, and if the summation:]]></summary></entry><entry><title type="html">Introduction of Principal Components Analysis (Chinese)</title><link href="https://zeyun-zhong.github.io/blog/2021/Introduction-of-Principal-Components-Analysis-(Chinese)/" rel="alternate" type="text/html" title="Introduction of Principal Components Analysis (Chinese)"/><published>2021-08-30T00:00:00+00:00</published><updated>2021-08-30T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2021/Introduction-of-Principal-Components-Analysis-(Chinese)</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2021/Introduction-of-Principal-Components-Analysis-(Chinese)/"><![CDATA[<h2 id="引入">引入</h2> <p>维度是数据科学中的一个重要话题。维度是数据集的所有特征。例如，对于一个包含音乐作品的数据集而言，维度可以是流派、作品的长度、乐器的数量等等。我们可以把所有这些维度想象成不同的列。当只有两个维度时，绘图就非常方便：可以使用x轴和y轴。如果有几十个或几百个维度，那也是类似的，只是会更难将其可视化。</p> <p>当有很多维度时，难免其中一些维度是相关的。例如，一首乐曲的流派会与乐曲中的乐器相关，等等。那么这些维度就是冗余的，因此实际上我们可以使用更少的维度来描述同一个对象。减少维度的一个方法是只保留部分维度而舍去其他维度，但是这样我们可能会失去一些好的信息。如果有一种方法可以减少这些维度，同时保留数据集中的重要信息，那就好了。没错，这时候PCA就登场了。</p> <h2 id="两个目的">两个目的</h2> <p>主成分分析PCA是一种被广泛用于数据降维、有损数据压缩、特征提取等应用的技术。PCA为我们提供了一组新的维度，即<strong>主成分</strong>（PC）。每一个主成分都是数据集所有原特征的线性组合。这些主成分是有序的，第一主成分就是体现数据差异最大化的维度。此外，主成分之间是正交的（点积为0）。</p> <p>PCA的目的有两个：</p> <ul> <li><strong>最大化正交投影后数据的方差</strong>。也就是说想办法找到新的一组维度，使得在这些维度构成的空间上，样本间的差距最大。这样我们就能更好的分辨和描绘出每个独立的样本。</li> <li><strong>最小化重构损失</strong>。我们虽然想要使用更少的维度来描述原数据，但是也不希望重构的数据与原数据相差甚远。</li> </ul> <p>在分析这两个目的之前，我们来看一下重构这个概念。当数据投影到新维度空间时，投影数据的表示方式就是新维度空间的表示方式。这时如果我们想要计算重构损失，我们就要把投影数据转换成为原维度空间的表示方式。举个简单的例子，如下图所示，蓝点的坐标是(1,2)，投影到红轴上，投影点在红轴的表示方式是：$[1,2]\cdot[\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T = \frac{3}{\sqrt{2}}$。我们现在要计算重构损失，就要把橙点从红轴上再转换到原坐标系：$\frac{3}{\sqrt{2}}\cdot[\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]=(\frac{3}{2},\frac{3}{2})$。</p> <p><img src="/assets/images/Linear Algebra/proj_reconst2.png" alt="" class="align-center"/> <em>图 1. 二维数据（蓝点）在新维度（红轴）上的投影（橙点）。</em></p> <p>现在我们来分析一下这两个目的。这两个目的看起来虽然很不相同，但是实质上是一样的。</p> <p>我们先通过一张图来直观看待，如下图所示，图中的每一个点代表一个二维样本，可以看出这两个维度（x和y）是相关联的。我们可以通过投影这些点到一条穿过点云中心的线来重新描述这些数据。图中的黑线即我们要寻找的新的维度，黑线上的红点即原数据在新维度上的投影。这个新的维度是原维度x和y的线性组合。观看这张图我们会发现，当黑线转动到洋红线的时候：1）红点最为扩散（方差最大），2）平均重构损失（连结红点与蓝点的红线）最小。也就是说“最大方差”和“最小损失”是同时达到的。</p> <p><img src="/assets/images/Linear Algebra/PCA.gif" alt="" class="align-center"/> <em>图 2. 二维数据（蓝点）在新维度（黑线）上的投影（红点）。</em></p> <p>现在我们用公式来证明一下这个观察。让我们用$\boldsymbol{X}\in R ^{m\times n}$来表示去中心化的数据，其中$m$表示样本的数量，$n$表示每一个样本的维度。去中心化意味着数据已被平移，新的数据中心是零向量，那么现在数据的协方差矩阵就是：</p> \[\boldsymbol{\Sigma} = \frac{1}{m-1} (\boldsymbol{X}-\boldsymbol{\bar{X}})^T(\boldsymbol{X}-\boldsymbol{\bar{X}}) = \frac{1}{m-1} \boldsymbol{X}^T\boldsymbol{X}。\tag{1}\] <p>我们用一个单位向量$\boldsymbol{w}\in R^{n\times 1}$来作为第一主成分（方便起见，我们暂时只考虑第一主成分），因为新维度是原所有维度的线性组合，所以长度为$n$。那么数据在这一向量上的投影就是$\boldsymbol{X}<em>{proj} = \boldsymbol{X}\boldsymbol{w}$，$\boldsymbol{X}</em>{proj} \in R^{m\times 1}$。根据目的一，我们想最大化投影后数据的方差，即：</p> \[\begin{aligned} \boldsymbol{w} = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \mathrm{Var}(\boldsymbol{X}_{proj}) &amp;= \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \frac{1}{m-1} \boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w} \\ &amp;= \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w} \quad \text{subject to} \quad \boldsymbol{w}^T\boldsymbol{w}=1。 \end{aligned} \tag{2}\] <p>原数据的重构表示为$\boldsymbol{X}<em>{reconst} = \boldsymbol{X}</em>{proj}\boldsymbol{w}^T$，$\boldsymbol{X}_{reconst}\in R^{m\times n}$。根据目的二，我们要最小化重构损失，即：</p> \[\begin{aligned} \boldsymbol{w} &amp;= \underset{\boldsymbol{w}}{\mathrm{argmin}} \, || \boldsymbol{X} - \boldsymbol{X}_{reconst} ||_F^2 \\&amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \mathrm{Tr}\big((\boldsymbol{X}-\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)^T(\boldsymbol{X}-\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) \big)\\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X} - \boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T-\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}+\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X})}_{常数项，可省略} - \underbrace{2\cdot \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)}_{迹运算}+ \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{w}\boldsymbol{w}^T)}_{迹运算} \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, -2\cdot \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)+ \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)}_{单位向量，\boldsymbol{w}^T\boldsymbol{w}=1} \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmax}} \,\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \mathrm{Tr}(\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}) \\&amp; = \underset{\boldsymbol{w}}{\mathrm{argmax}} \,\boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w}\quad \text{subject to} \quad \boldsymbol{w}^T\boldsymbol{w}=1。 \end{aligned} \tag{3}\] <p>其中$||\boldsymbol{\cdot} ||_F$表示Frobenius范数，类似于向量的$L^2$范数。迹运算的部分请参考Deep Learning Book的<a href="https://www.deeplearningbook.org/contents/linear_algebra.html">2.10</a>小节。可见，PCA的这两个目的最终达到的效果是一样的。</p> <h2 id="求解">求解</h2> <p>现在有了公式就好办了，我们先用拉格朗日乘子法将有约束的优化问题转化成无约束的优化问题：</p> \[\boldsymbol{w} = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, L(\boldsymbol{w},\lambda) = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w} - \lambda(\boldsymbol{w}^T\boldsymbol{w}-1)。\tag{4}\] <p>对$\boldsymbol{w}$求导并置零来求得静态点（对矩阵求导的部分可参考<a href="https://zhuanlan.zhihu.com/p/24709748">这里</a>）：</p> \[\frac{\partial L}{\partial \boldsymbol{w}} = 2(\boldsymbol{\Sigma}\boldsymbol{w}-\lambda\boldsymbol{w}) = \boldsymbol{0}。\tag{5}\] <p>这样我们就得到了特征值的定义等式：$\boldsymbol{\Sigma \boldsymbol{w}} = \lambda\boldsymbol{w}$，由此可知$\lambda$是协方差矩阵$\boldsymbol{\Sigma}$的特征值。将此式代入（4）可得，第一主成分即$\boldsymbol{\Sigma}$的最大特征值所对应的特征向量。值得一提的是，$\boldsymbol{\Sigma}$和$\boldsymbol{X}^T\boldsymbol{X}$的特征向量矩阵都是一样的，只不过特征值存在着系数的差别。因此，对$\boldsymbol{\Sigma}$和$\boldsymbol{X}^T\boldsymbol{X}$进行特征值分解都会获得同样的结果。</p> <p>如果我们要求前$l$个主成分，我们只需要用$\boldsymbol{W}\in R ^{n\times l}$来代替式（2）和（3）中的单位向量$\boldsymbol{w}$即可。$\boldsymbol{W}$中列向量（主成分）互相正交，因此$\boldsymbol{W}^T\boldsymbol{W}=\boldsymbol{I}_l$。根据归纳法（详情请参考<a href="https://math.stackexchange.com/questions/2280047/how-to-prove-pca-using-induction">这里</a>），前$l$个主成分就是$\boldsymbol{\Sigma}$的$l$个最大特征值所对应的特征向量。</p> <h2 id="示例分析">示例分析</h2> <p>这里我们用一张假色红外图$\boldsymbol{I}$举个例子。这张红外图由三个通道组成，分别是NIR（近红外），R和G。这张图的分辨率是$255\times 607$，因此$\boldsymbol{X}$的大小是$154785\times 3$。在开始下面的操作之前，我们先将$\boldsymbol{X}$去中心化：$\boldsymbol{X} = \boldsymbol{X_{ori}} - \boldsymbol{\bar X}$。</p> <p><img src="/assets/images/Linear Algebra/houseigb.jpg" alt="" class="align-center"/> <em>图 3. 假色红外图。</em></p> <p>通过计算得出，原图的协方差矩阵是：</p> \[\boldsymbol{\Sigma} = \frac{1}{m-1} \boldsymbol{X}^T\boldsymbol{X} = \left[\begin{matrix} 6324.4 &amp; 3013.5 &amp; 2952.5 \\ 3013.5 &amp; 2916.9 &amp; 2642.4 \\ 2952.5 &amp; 2642.4 &amp; 2595.2 \end{matrix} \right]。\] <p>根据<a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">相关系数</a>公式：$\rho_{(A, B)} = \frac{\text{cov}(A, B)}{\sigma_A \sigma_B}$，可计算出NIR和R的相关系数是70.2%，NIR和G的系数是72.9%，R和G的系数是96.0%。可见，这三个维度是相互关联的。接下来我们应用PCA，对协方差矩阵进行特征分解，会得到三个特征值$\boldsymbol{\lambda}$（10107，1623，106）和相对应的三个特征向量$\boldsymbol{W}$（主成分）（$[0.74, 0.48, 0.46]^T，[0.67, -0.57, -0.48]^T，[-0.03, -0.67, 0.74]^T$）。将原图投影到特征空间（$\boldsymbol{X}\boldsymbol{W}$），可得到新的协方差矩阵：</p> \[\boldsymbol{\Sigma}_{pca} = \left[\begin{matrix} 10107 &amp; 0 &amp; 0 \\ 0 &amp; 1623 &amp; 0 \\ 0 &amp; 0 &amp; 106 \end{matrix} \right]。\] <p>这时候会有同学发现，这个新协方差矩阵不就是把上面那三个特征值塞进去了吗？</p> <p>没错，确实是这样。因为：</p> \[\begin{aligned} \boldsymbol{\Sigma}_{pca} &amp;= \frac{1}{m-1} \boldsymbol{W}^T \boldsymbol{X}^T \boldsymbol{X} \boldsymbol{W} = \boldsymbol{W}^T\boldsymbol{\Sigma}\boldsymbol{W} \\ &amp; = \boldsymbol{W}^T\boldsymbol{\Sigma}[\boldsymbol{w}_1, \boldsymbol{w}_2, \boldsymbol{w}_3] = \boldsymbol{W}^T[\lambda_1\boldsymbol{w}_1, \lambda_2\boldsymbol{w}_2, \lambda_3\boldsymbol{w}_3] = \text{diag}(\boldsymbol{\lambda})。 \end{aligned}\] <p>结合新的协方差矩阵和下图，我们可以得出下列结论：</p> <ul> <li>经过投影之后的数据，维度之间不再相关联（协方差为0）。</li> <li>在第一主成分上，数据的方差最大，且包含信息最多。在最后一个主成分上，数据的方差最小，同时也包含着最少的信息。</li> </ul> <p><img src="/assets/images/Linear Algebra/pca_example.png" alt="" class="align-center"/> <em>图 4. 原图和投影之后的图。</em></p> <h2 id="总结">总结</h2> <p>主成分分析PCA是一种被广泛用于数据降维、有损数据压缩、特征提取等应用的技术。PCA会找到一组新的维度（主成分），这些维度之间互相正交。分析PCA，你会发现PCA总是会先：1）找到当前n维空间中数据差异最大的维度，2）将数据投影到与该维度正交的维度空间（n-1）。</p> <p>这里再总结一下PCA的步骤：</p> <ul> <li>对数据去中心化</li> <li>计算协方差矩阵，注：这里除或不除样本数量m或m−1对求出的特征向量没影响</li> <li>对协方差矩阵进行特征分解</li> <li>选取特征值最大的几个维度进行数据映射，舍去较小特征值对应的维度，从而实现降维的目的</li> </ul> <p>以前上课的对这一块儿一直一知半解，最近读Deep Learning Book看到这一块，再结合网上看的一些文章，总结出这篇文章，方便自己以后回顾，也希望能帮助一些初学者。</p> <p>有错误欢迎指出，共同进步。</p> <h2 id="参考">参考</h2> <ul> <li>Deep Learning Book <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">第二章</a></li> <li>https://math.stackexchange.com/questions/2314520/find-maximum-of-matrix-trace</li> <li>https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/2700#2700</li> <li>https://stats.stackexchange.com/questions/217995/what-is-an-intuitive-explanation-for-how-pca-turns-from-a-geometric-problem-wit</li> <li>https://stats.stackexchange.com/questions/32174/pca-objective-function-what-is-the-connection-between-maximizing-variance-and-m/136072#136072</li> <li>https://math.stackexchange.com/questions/2280047/how-to-prove-pca-using-induction</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[引入 维度是数据科学中的一个重要话题。维度是数据集的所有特征。例如，对于一个包含音乐作品的数据集而言，维度可以是流派、作品的长度、乐器的数量等等。我们可以把所有这些维度想象成不同的列。当只有两个维度时，绘图就非常方便：可以使用x轴和y轴。如果有几十个或几百个维度，那也是类似的，只是会更难将其可视化。 当有很多维度时，难免其中一些维度是相关的。例如，一首乐曲的流派会与乐曲中的乐器相关，等等。那么这些维度就是冗余的，因此实际上我们可以使用更少的维度来描述同一个对象。减少维度的一个方法是只保留部分维度而舍去其他维度，但是这样我们可能会失去一些好的信息。如果有一种方法可以减少这些维度，同时保留数据集中的重要信息，那就好了。没错，这时候PCA就登场了。 两个目的 主成分分析PCA是一种被广泛用于数据降维、有损数据压缩、特征提取等应用的技术。PCA为我们提供了一组新的维度，即主成分（PC）。每一个主成分都是数据集所有原特征的线性组合。这些主成分是有序的，第一主成分就是体现数据差异最大化的维度。此外，主成分之间是正交的（点积为0）。 PCA的目的有两个： 最大化正交投影后数据的方差。也就是说想办法找到新的一组维度，使得在这些维度构成的空间上，样本间的差距最大。这样我们就能更好的分辨和描绘出每个独立的样本。 最小化重构损失。我们虽然想要使用更少的维度来描述原数据，但是也不希望重构的数据与原数据相差甚远。 在分析这两个目的之前，我们来看一下重构这个概念。当数据投影到新维度空间时，投影数据的表示方式就是新维度空间的表示方式。这时如果我们想要计算重构损失，我们就要把投影数据转换成为原维度空间的表示方式。举个简单的例子，如下图所示，蓝点的坐标是(1,2)，投影到红轴上，投影点在红轴的表示方式是：$[1,2]\cdot[\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T = \frac{3}{\sqrt{2}}$。我们现在要计算重构损失，就要把橙点从红轴上再转换到原坐标系：$\frac{3}{\sqrt{2}}\cdot[\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]=(\frac{3}{2},\frac{3}{2})$。 图 1. 二维数据（蓝点）在新维度（红轴）上的投影（橙点）。 现在我们来分析一下这两个目的。这两个目的看起来虽然很不相同，但是实质上是一样的。 我们先通过一张图来直观看待，如下图所示，图中的每一个点代表一个二维样本，可以看出这两个维度（x和y）是相关联的。我们可以通过投影这些点到一条穿过点云中心的线来重新描述这些数据。图中的黑线即我们要寻找的新的维度，黑线上的红点即原数据在新维度上的投影。这个新的维度是原维度x和y的线性组合。观看这张图我们会发现，当黑线转动到洋红线的时候：1）红点最为扩散（方差最大），2）平均重构损失（连结红点与蓝点的红线）最小。也就是说“最大方差”和“最小损失”是同时达到的。 图 2. 二维数据（蓝点）在新维度（黑线）上的投影（红点）。 现在我们用公式来证明一下这个观察。让我们用$\boldsymbol{X}\in R ^{m\times n}$来表示去中心化的数据，其中$m$表示样本的数量，$n$表示每一个样本的维度。去中心化意味着数据已被平移，新的数据中心是零向量，那么现在数据的协方差矩阵就是： \[\boldsymbol{\Sigma} = \frac{1}{m-1} (\boldsymbol{X}-\boldsymbol{\bar{X}})^T(\boldsymbol{X}-\boldsymbol{\bar{X}}) = \frac{1}{m-1} \boldsymbol{X}^T\boldsymbol{X}。\tag{1}\] 我们用一个单位向量$\boldsymbol{w}\in R^{n\times 1}$来作为第一主成分（方便起见，我们暂时只考虑第一主成分），因为新维度是原所有维度的线性组合，所以长度为$n$。那么数据在这一向量上的投影就是$\boldsymbol{X}{proj} = \boldsymbol{X}\boldsymbol{w}$，$\boldsymbol{X}{proj} \in R^{m\times 1}$。根据目的一，我们想最大化投影后数据的方差，即： \[\begin{aligned} \boldsymbol{w} = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \mathrm{Var}(\boldsymbol{X}_{proj}) &amp;= \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \frac{1}{m-1} \boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w} \\ &amp;= \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w} \quad \text{subject to} \quad \boldsymbol{w}^T\boldsymbol{w}=1。 \end{aligned} \tag{2}\] 原数据的重构表示为$\boldsymbol{X}{reconst} = \boldsymbol{X}{proj}\boldsymbol{w}^T$，$\boldsymbol{X}_{reconst}\in R^{m\times n}$。根据目的二，我们要最小化重构损失，即： \[\begin{aligned} \boldsymbol{w} &amp;= \underset{\boldsymbol{w}}{\mathrm{argmin}} \, || \boldsymbol{X} - \boldsymbol{X}_{reconst} ||_F^2 \\&amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \mathrm{Tr}\big((\boldsymbol{X}-\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)^T(\boldsymbol{X}-\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) \big)\\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X} - \boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T-\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}+\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X})}_{常数项，可省略} - \underbrace{2\cdot \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)}_{迹运算}+ \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T\boldsymbol{w}\boldsymbol{w}^T)}_{迹运算} \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmin}} \, -2\cdot \mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)+ \underbrace{\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T)}_{单位向量，\boldsymbol{w}^T\boldsymbol{w}=1} \\ &amp; = \underset{\boldsymbol{w}}{\mathrm{argmax}} \,\mathrm{Tr}(\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}\boldsymbol{w}^T) = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \mathrm{Tr}(\boldsymbol{w}^T\boldsymbol{X}^T\boldsymbol{X}\boldsymbol{w}) \\&amp; = \underset{\boldsymbol{w}}{\mathrm{argmax}} \,\boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w}\quad \text{subject to} \quad \boldsymbol{w}^T\boldsymbol{w}=1。 \end{aligned} \tag{3}\] 其中$||\boldsymbol{\cdot} ||_F$表示Frobenius范数，类似于向量的$L^2$范数。迹运算的部分请参考Deep Learning Book的2.10小节。可见，PCA的这两个目的最终达到的效果是一样的。 求解 现在有了公式就好办了，我们先用拉格朗日乘子法将有约束的优化问题转化成无约束的优化问题： \[\boldsymbol{w} = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, L(\boldsymbol{w},\lambda) = \underset{\boldsymbol{w}}{\mathrm{argmax}} \, \boldsymbol{w}^T\boldsymbol{\Sigma}\boldsymbol{w} - \lambda(\boldsymbol{w}^T\boldsymbol{w}-1)。\tag{4}\] 对$\boldsymbol{w}$求导并置零来求得静态点（对矩阵求导的部分可参考这里）： \[\frac{\partial L}{\partial \boldsymbol{w}} = 2(\boldsymbol{\Sigma}\boldsymbol{w}-\lambda\boldsymbol{w}) = \boldsymbol{0}。\tag{5}\] 这样我们就得到了特征值的定义等式：$\boldsymbol{\Sigma \boldsymbol{w}} = \lambda\boldsymbol{w}$，由此可知$\lambda$是协方差矩阵$\boldsymbol{\Sigma}$的特征值。将此式代入（4）可得，第一主成分即$\boldsymbol{\Sigma}$的最大特征值所对应的特征向量。值得一提的是，$\boldsymbol{\Sigma}$和$\boldsymbol{X}^T\boldsymbol{X}$的特征向量矩阵都是一样的，只不过特征值存在着系数的差别。因此，对$\boldsymbol{\Sigma}$和$\boldsymbol{X}^T\boldsymbol{X}$进行特征值分解都会获得同样的结果。 如果我们要求前$l$个主成分，我们只需要用$\boldsymbol{W}\in R ^{n\times l}$来代替式（2）和（3）中的单位向量$\boldsymbol{w}$即可。$\boldsymbol{W}$中列向量（主成分）互相正交，因此$\boldsymbol{W}^T\boldsymbol{W}=\boldsymbol{I}_l$。根据归纳法（详情请参考这里），前$l$个主成分就是$\boldsymbol{\Sigma}$的$l$个最大特征值所对应的特征向量。 示例分析 这里我们用一张假色红外图$\boldsymbol{I}$举个例子。这张红外图由三个通道组成，分别是NIR（近红外），R和G。这张图的分辨率是$255\times 607$，因此$\boldsymbol{X}$的大小是$154785\times 3$。在开始下面的操作之前，我们先将$\boldsymbol{X}$去中心化：$\boldsymbol{X} = \boldsymbol{X_{ori}} - \boldsymbol{\bar X}$。 图 3. 假色红外图。 通过计算得出，原图的协方差矩阵是： \[\boldsymbol{\Sigma} = \frac{1}{m-1} \boldsymbol{X}^T\boldsymbol{X} = \left[\begin{matrix} 6324.4 &amp; 3013.5 &amp; 2952.5 \\ 3013.5 &amp; 2916.9 &amp; 2642.4 \\ 2952.5 &amp; 2642.4 &amp; 2595.2 \end{matrix} \right]。\] 根据相关系数公式：$\rho_{(A, B)} = \frac{\text{cov}(A, B)}{\sigma_A \sigma_B}$，可计算出NIR和R的相关系数是70.2%，NIR和G的系数是72.9%，R和G的系数是96.0%。可见，这三个维度是相互关联的。接下来我们应用PCA，对协方差矩阵进行特征分解，会得到三个特征值$\boldsymbol{\lambda}$（10107，1623，106）和相对应的三个特征向量$\boldsymbol{W}$（主成分）（$[0.74, 0.48, 0.46]^T，[0.67, -0.57, -0.48]^T，[-0.03, -0.67, 0.74]^T$）。将原图投影到特征空间（$\boldsymbol{X}\boldsymbol{W}$），可得到新的协方差矩阵： \[\boldsymbol{\Sigma}_{pca} = \left[\begin{matrix} 10107 &amp; 0 &amp; 0 \\ 0 &amp; 1623 &amp; 0 \\ 0 &amp; 0 &amp; 106 \end{matrix} \right]。\] 这时候会有同学发现，这个新协方差矩阵不就是把上面那三个特征值塞进去了吗？ 没错，确实是这样。因为： \[\begin{aligned} \boldsymbol{\Sigma}_{pca} &amp;= \frac{1}{m-1} \boldsymbol{W}^T \boldsymbol{X}^T \boldsymbol{X} \boldsymbol{W} = \boldsymbol{W}^T\boldsymbol{\Sigma}\boldsymbol{W} \\ &amp; = \boldsymbol{W}^T\boldsymbol{\Sigma}[\boldsymbol{w}_1, \boldsymbol{w}_2, \boldsymbol{w}_3] = \boldsymbol{W}^T[\lambda_1\boldsymbol{w}_1, \lambda_2\boldsymbol{w}_2, \lambda_3\boldsymbol{w}_3] = \text{diag}(\boldsymbol{\lambda})。 \end{aligned}\] 结合新的协方差矩阵和下图，我们可以得出下列结论： 经过投影之后的数据，维度之间不再相关联（协方差为0）。 在第一主成分上，数据的方差最大，且包含信息最多。在最后一个主成分上，数据的方差最小，同时也包含着最少的信息。 图 4. 原图和投影之后的图。 总结 主成分分析PCA是一种被广泛用于数据降维、有损数据压缩、特征提取等应用的技术。PCA会找到一组新的维度（主成分），这些维度之间互相正交。分析PCA，你会发现PCA总是会先：1）找到当前n维空间中数据差异最大的维度，2）将数据投影到与该维度正交的维度空间（n-1）。 这里再总结一下PCA的步骤： 对数据去中心化 计算协方差矩阵，注：这里除或不除样本数量m或m−1对求出的特征向量没影响 对协方差矩阵进行特征分解 选取特征值最大的几个维度进行数据映射，舍去较小特征值对应的维度，从而实现降维的目的 以前上课的对这一块儿一直一知半解，最近读Deep Learning Book看到这一块，再结合网上看的一些文章，总结出这篇文章，方便自己以后回顾，也希望能帮助一些初学者。 有错误欢迎指出，共同进步。 参考 Deep Learning Book 第二章 https://math.stackexchange.com/questions/2314520/find-maximum-of-matrix-trace https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues/2700#2700 https://stats.stackexchange.com/questions/217995/what-is-an-intuitive-explanation-for-how-pca-turns-from-a-geometric-problem-wit https://stats.stackexchange.com/questions/32174/pca-objective-function-what-is-the-connection-between-maximizing-variance-and-m/136072#136072 https://math.stackexchange.com/questions/2280047/how-to-prove-pca-using-induction]]></summary></entry><entry><title type="html">Columnspace and Nullspace of a Matrix A and the Solvability of Ax = b</title><link href="https://zeyun-zhong.github.io/blog/2021/Columnspace-and-Nullspace-of-a-Matrix-A-and-the-Solvability-of-Ax=b/" rel="alternate" type="text/html" title="Columnspace and Nullspace of a Matrix A and the Solvability of Ax=b"/><published>2021-08-17T00:00:00+00:00</published><updated>2021-08-17T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2021/Columnspace-and-Nullspace-of-a-Matrix-A-and-the-Solvability-of-Ax=b</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2021/Columnspace-and-Nullspace-of-a-Matrix-A-and-the-Solvability-of-Ax=b/"><![CDATA[<h2 id="1-column-space">1. Column Space</h2> <p>The column space denoted by $\boldsymbol{C(A)}$ contains all linear combinations of the columns of matrix $\boldsymbol{A}$ ($m\times n$). It is a subspace of $\mathbb{R}^m$, since the largest dimension it can reach is the dimension of the $\boldsymbol{b}$-vector. We illustrate by a system of $m=3$ equations and $n=2$ unknowns:</p> \[\left[ \begin{matrix} 1 &amp; 0 \\ 5 &amp; 4 \\ 2 &amp; 4 \end{matrix} \right] \left[ \begin{matrix} u \\ v \end{matrix} \right] = \left[ \begin{matrix} b_1 \\ b_2 \\b_3 \end{matrix} \right]. \tag{1}\] <p>As we have more equations than unknowns in this example, and this usually means there will be no solution. One example is illustrated in the figure below. Since there is no point which belongs to all of three lines, the system has no solution.</p> <p><img src="/assets/images/Linear Algebra/overdetermined_system.png" alt="" class="align-center"/> <em>Figure 1. Linear System with 3 Equations and 2 Unknows.</em></p> <p>But there is still chance that the system will be solvable for a subset of all possible $\boldsymbol{b}$s. One way to check this is to check if $\boldsymbol{b}$ lies in the column space. We can reformulate the equation (1) by columns:</p> \[u\left[ \begin{matrix} 1 \\ 5 \\ 2 \end{matrix} \right] + v\left[ \begin{matrix} 0 \\ 4 \\ 4 \end{matrix} \right] = \left[ \begin{matrix} b_1 \\ b_2 \\ b_3 \end{matrix} \right]. \tag{2}\] <p>We can describe all combinations of the two columns geometrically: $\boldsymbol{Ax}=\boldsymbol{b}$ can be solved if and only if $\boldsymbol{b}$ lies in the plane that is spanned by the two column vectors (Figure 2). If $\boldsymbol{b}$ lies off the plane, then it is not a combination of the two columns, corresponding to no solution of the linear system.</p> <p><img src="/assets/images/Linear Algebra/columnspace.png" alt="" class="align-center"/> <em>Figure 2. The column space C(A), a plane in three-dimensional space.</em></p> <h2 id="2-nullspace">2. Nullspace</h2> <p>The nullspace of a matrix consists of all vectors $\boldsymbol{x}$ such that $\boldsymbol{Ax}=\boldsymbol{0}$. It is denoted by $\boldsymbol{N(A)}$. It is a subspace of $\mathbb{R}^n$, since the $\boldsymbol{x}$-vector is $n$-dimensional.</p> <h2 id="3-echelon-form-and-row-reduced-form">3. Echelon Form and Row Reduced Form</h2> <p>Let us now review the echelon form und the row reduced echelon form of a matrix $\boldsymbol{A}$. Suppose we have a 3 by 4 matrix:</p> \[\boldsymbol{A} = \left[ \begin{matrix} 1 &amp; 3 &amp; 3 &amp; 2 \\ 2 &amp; 6 &amp; 9 &amp; 7 \\ -1 &amp; -3 &amp; 3 &amp; 4 \end{matrix} \right]\] <p>After doing <a href="https://en.wikipedia.org/wiki/Gaussian_elimination">row reduction</a>, we get the echelon matrix $\boldsymbol{U}$:</p> \[\boldsymbol{U} = \left[ \begin{matrix} \mathbf{1} &amp; 3 &amp; 3 &amp; 2 \\ 0 &amp; 0 &amp; \mathbf{3} &amp; 3 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{matrix} \right]\] <p>The first nonzero entries in their rows are called pivots (in bold typeface). The rows contain pivots are the pivot rows and the columns contain pivot are the pivot columns. In this example, we have two pivot rows and two pivot columns.</p> <p>We can go further than $\boldsymbol{U}$, to make the matrix even simpler: first make all pivots 1 and then produce zero above the pivots. The final result is the reduced row echelon form $\boldsymbol{R}$.</p> \[\left[ \begin{matrix} 1 &amp; 3 &amp; 3 &amp; 2 \\ 0 &amp; 0 &amp; 3 &amp; 3 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{matrix} \right] \rightarrow \left[ \begin{matrix} 1 &amp; 3 &amp; 3 &amp; 2 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{matrix} \right] \rightarrow \left[ \begin{matrix} 1 &amp; 3 &amp; 0 &amp; -1 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{matrix} \right] = \boldsymbol{R}.\] <h2 id="4-pivot-variables-free-variables-and-rank">4. Pivot Variables, Free Variables and Rank</h2> <p>The pivots are crucial to read off all the solutions to $\boldsymbol{Rx}=\boldsymbol{0}$.</p> \[\boldsymbol{Rx}= \left[ \begin{matrix} \mathbf{1} &amp; 3 &amp; \mathbf{0} &amp; -1 \\ \mathbf{0} &amp; 0 &amp; \mathbf{1} &amp; 1 \\ \mathbf{0} &amp; 0 &amp; \mathbf{0} &amp; 0 \end{matrix} \right] \left[ \begin{matrix} u \\ v \\ w \\ y \end{matrix} \right] = \left[ \begin{matrix} 0 \\ 0 \\ 0 \end{matrix} \right] \tag{3}\] <p>The unknows $u$, $v$, $w$, $y$ can be divided into two groups: <strong>pivot variables</strong> which correspond to the pivot columns (in boldface), and <strong>free variables</strong>, corresponging to columns without pivots. Accoring to Equation 3, the pivot variables are completely determined in terms of the freee variables $v$ and $y$:</p> \[\begin{aligned} u + 3v - y &amp;= 0 \quad &amp;\text{yields} \quad u &amp;= -3v + y \\ w + y &amp;= 0 \quad &amp;\text{yields} \quad w &amp;= -y \end{aligned} \tag{4}\] <p>If we set $v=1, y=0$ and $v=0, y=1$, then we get two special solutions. The complete solution to $\boldsymbol{Rx}=\mathbf{0}$, or equivalently to $\boldsymbol{Ax}=\mathbf{0}$, is a combination of these two special solutions:</p> \[\boldsymbol{x} = \left[ \begin{matrix} -3v+y \\ v \\ -y \\ y \end{matrix} \right] =v \left[ \begin{matrix} -3 \\ 1 \\ 0 \\ 0 \end{matrix} \right] + y \left[ \begin{matrix} 1 \\ 0 \\ -1 \\ 1 \end{matrix} \right]. \tag{5}\] <p>Each free variable produces its own special solution. The nullspace $\boldsymbol{N(A)}$ is therefore generated by these special solutions and the dimension of the nullspace corresponds to the number of the free variables.</p> <p>On the other side, the pivot variables count for the column space. The number of pivot variables $r$ corresponds to the number of independent columns (and independent rows) of matrix $\boldsymbol{A}$, which is also called the <strong>rank</strong> denoted by $rank(\boldsymbol{A})$.</p> <h2 id="5-solving-axb-uxc-and-rxd">5. Solving Ax=b, Ux=c, and Rx=d</h2> <p>The case $\boldsymbol{b} \neq \mathbf{0}$ is quite different from $\boldsymbol{b} = \mathbf{0}$. The row operations on $\boldsymbol{A}$ must act also on the right-hand side ($\boldsymbol{b}$). For the original example $\boldsymbol{Ax}=\boldsymbol{b}$, apply to both sides the operations that led from $\boldsymbol{A}$ to $\boldsymbol{U}$. The result is an upper triangular system $\boldsymbol{Ux} = \boldsymbol{c}$:</p> \[\left[ \begin{matrix} 1 &amp; 3 &amp; 3 &amp; 2 \\ 0 &amp; 0 &amp; 3 &amp; 3 \\ 0 &amp; 0 &amp; 0 &amp; 0 \end{matrix} \right] \left[ \begin{matrix} u \\ v \\ w \\ y \end{matrix} \right] = \left[ \begin{matrix} b_1 \\ b_2 - 2b_1 \\ b_3 - 2b_2 + 5b_1 \end{matrix} \right]. \tag{6}\] <p>To make the system solvable, the vector $\boldsymbol{b}$ must lie in the column space generated by the pivot columns (column 1 and 3 in this case). Equivalently, all vectors $\boldsymbol{b}$ in that space must satisfy $b_3 - 2b_2 + 5b_1 = 0$. Here we choose $\boldsymbol{b} = (1,5,5)$ and back-substitution gives:</p> \[\begin{aligned} 3w + 3y &amp;= 3 \quad &amp;\text{or} \quad w &amp;= 1 - y \\ u + 3v + 3w + 2y &amp;= 1 \quad &amp;\text{or} \quad u &amp;= -2 - 3v + y. \end{aligned} \tag{7}\] <p>Setting all free variables ($v$ and $y$) to zero, we get a particular solution $\boldsymbol{x_p} = (-2, 0, 1, 0)$. Since every solution to $\boldsymbol{Ax}=\boldsymbol{b}$ is the sum of one particular solution and a solution to $\boldsymbol{Ax}=\mathbf{0}$:</p> \[\boldsymbol{x}_\text{complete} = \boldsymbol{x}_\text{particular} + \boldsymbol{x}_\text{nullspace}.\] <p>The complete solution would be:</p> \[\boldsymbol{x} = \left[ \begin{matrix} u \\ v\\ w \\ y \end{matrix} \right] = \left[ \begin{matrix} -2 \\ 0 \\ 1 \\ 0 \end{matrix} \right] + v \left[ \begin{matrix} -3 \\ 1 \\ 0 \\ 0 \end{matrix} \right] + y \left[ \begin{matrix} 1 \\ 0 \\ -1 \\ 1 \end{matrix} \right]. \tag{8}\] <p>When the equation was $\boldsymbol{Ax}=\mathbf{0}$, the particular solution was the zero vector! The reduced form $\boldsymbol{R}$ makes this solution even clearer. However, this process will not be repeated here.</p> <h2 id="6-number-of-possible-solutions-of-axb">6. Number of Possible Solutions of Ax=b</h2> <p>After introducing the previous sections, we are finally able to conclude the solvability of a linear system $\boldsymbol{Ax}=\mathbf{b}$ and the possible number of solutions.</p> <p>Still remember the definition of the rank introduced in Section 4.? It is the number of pivot variables and also the maximal number of linearly independent columns (and rows) of matrix $\boldsymbol{A}$. It is crucial for analysis of the solvability of a linear system.</p> <ul> <li>$r = m = n$: Since the number of free variables ($n-r$) equals zero, there are no free variables, leading to one single solution. The matrix $\boldsymbol{A}$ is invertible.</li> <li>$r = n &lt; m$: There are still no free variables, since $n-r = 0$. However, there are zero rows in the echelon form $\boldsymbol{U}$ or in the reduced form $\boldsymbol{R}$, like in Equation 6. This means, there are certain constraints the $\boldsymbol{b}$-vector must satisfy. Thus, there could be one single solution or no solution. Another way to think of it: The dimension of the column space is smaller than the dimension of the $\boldsymbol{b}$-vector. If $\boldsymbol{b}$ lies off the column space, then there is no solution.</li> <li>$r = m &lt; n$: There are free variables, corresponding to infinitely many solutions.</li> <li>$r &lt; m$, $r &lt; n$: There are free variables and zero rows in $\boldsymbol{U}$ and $\boldsymbol{R}$. So there will be either infinitely many solutions or no solution.</li> </ul> <p>Here is a table to summarize the conclusions above:</p> <table> <thead> <tr> <th> </th> <th>No. of free variables</th> <th>No. of zero rows in $\boldsymbol{U}$ or $\boldsymbol{R}$</th> <th>No. of possible solutions</th> </tr> </thead> <tbody> <tr> <td>$r = m = n$</td> <td>0</td> <td>0</td> <td>1</td> </tr> <tr> <td>$r = n &lt; m$</td> <td>0</td> <td>$m-r$</td> <td>0 or 1</td> </tr> <tr> <td>$r = m &lt; n$</td> <td>$n-r$</td> <td>0</td> <td>$\infty$</td> </tr> <tr> <td>$r &lt; m$, $r &lt; n$</td> <td>$n-r$</td> <td>$m-r$</td> <td>0 or $\infty$</td> </tr> </tbody> </table> <h2 id="reference">Reference</h2> <ul> <li>Strang, G. (2006). Linear Algebra and Its Applications, 4th Edition (4th edition). Belmont, CA: Cengage Learning.</li> <li><a href="https://www.youtube.com/watch?v=9Q1q7s1jTzU&amp;list=PL49CF3715CB9EF31D&amp;index=8&amp;ab_channel=MITOpenCourseWare">Lectures on Linear Algebra from Gilbert Strang</a></li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[1. Column Space The column space denoted by $\boldsymbol{C(A)}$ contains all linear combinations of the columns of matrix $\boldsymbol{A}$ ($m\times n$). It is a subspace of $\mathbb{R}^m$, since the largest dimension it can reach is the dimension of the $\boldsymbol{b}$-vector. We illustrate by a system of $m=3$ equations and $n=2$ unknowns:]]></summary></entry><entry><title type="html">Introduction of Common Optimizers in Deep Learning</title><link href="https://zeyun-zhong.github.io/blog/2021/Introduction-of-Common-Optimizers-in-Deep-Learning/" rel="alternate" type="text/html" title="Introduction of Common Optimizers in Deep Learning"/><published>2021-08-15T00:00:00+00:00</published><updated>2021-08-15T00:00:00+00:00</updated><id>https://zeyun-zhong.github.io/blog/2021/Introduction-of-Common-Optimizers-in-Deep-Learning</id><content type="html" xml:base="https://zeyun-zhong.github.io/blog/2021/Introduction-of-Common-Optimizers-in-Deep-Learning/"><![CDATA[<h2 id="basic-algorithms">Basic Algorithms</h2> <h3 id="stochastic-gradient-descent-sgd">Stochastic Gradient Descent (SGD)</h3> <p>Stochastic gradient descent is an extension of the gradient descent algorithm. Instead of being computed on the entire training sets, the SGD is computed on one minibatch drawn uniformly from the training set. The insight behind this is that the gradient is an expectation and the expectation may be approximately estimated using a small set of samples.</p> \[\begin{aligned} \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_\theta \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{\theta} &amp;\leftarrow \boldsymbol{\theta} - \epsilon \boldsymbol{g} \end{aligned}\] <p><img src="/assets/images/Optimizer/SGD_without_momentum.gif" alt="" class="align-center"/> <em>Figure 1. SGD without momentum.</em></p> <p>Challenges:</p> <ul> <li>Prone to oscillation. When the horizontal and vertical gradients are different (c.f. Fig. 1), the horizontal gradient updates slowly, while the vertical gradients updates quickly, as the learning rate for gradient updates in each direction is the same, causing oscillation in vertical direction.</li> <li>Difficult to choose a proper learning rate. As shown in Figure 1, a too large learning rate can hinder convergence or cause oscillation (vertical), while a too small learning rate leads to slow convergence (horizontal).</li> <li>Saddle points, i.e. points where one dimension slopes up and another slopes down. The gradient is close to zero in all dimensions, which makes it hard for SGD to escape.</li> </ul> <h3 id="momentum">Momentum</h3> <p>The momentum algorithm introduces a variable $v$ that plays the role of velocity, set to an exponentially decay average of the negative gradient.</p> \[\begin{aligned} \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_\theta \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{v} &amp;\leftarrow \alpha\boldsymbol{v}-\epsilon\boldsymbol{g} \\ \boldsymbol{\theta} &amp;\leftarrow \boldsymbol{\theta} + \boldsymbol{v} \end{aligned}\] <p>Momentum helps accelerate SGD in the relevant direction and dampens oscillations as can be seen in Figure 2. The update step size is largest when many successive gradients point in exactly the same direction. In Figure 2, the horizontal gradients always point to the right and thus, will be updated faster.</p> <p><img src="/assets/images/Optimizer/SGD_with_momentum.gif" alt="" class="align-center"/> <em>Figure 2. SGD with momentum.</em></p> <p>As this algorithm considers the gradient from the previous time step, the saddle point of current step could be escaped, although the current gradient is close to zero. Common values of the momentum term $\alpha$ used in practice include 0.5, 0.9 and 0.99.</p> <h3 id="nesterov-momentum">Nesterov Momentum</h3> <p>Nesterov momentum is a slightly different version of the momentum update. The gradient now is evaluated after the current velocity is applied. Thus one can interpret Nesterov momentum as attempting to add a <strong>correction factor</strong> to the standard method of momentum.</p> <p><img src="/assets/images/Optimizer/nesterov.jpeg" alt="" class="align-center"/> <em>Figure 3. Difference between Momentum and Nesterov momentum.</em></p> <p>The update rules are given by:</p> \[\begin{aligned} \hat{\boldsymbol{\theta}} &amp;\leftarrow \boldsymbol{\theta} + \alpha \boldsymbol{v} \\ \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_{\hat{\theta}} \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{v} &amp;\leftarrow \alpha\boldsymbol{v}-\epsilon\boldsymbol{g} \\ \boldsymbol{\theta} &amp;\leftarrow \hat{\boldsymbol{\theta}} -\epsilon\boldsymbol{g} \end{aligned}\] <h2 id="algorithms-with-adaptive-learning-rates">Algorithms with Adaptive Learning Rates</h2> <h3 id="adagrad">AdaGrad</h3> <p>The AdaGrad algorithm individually adapts the learning rates of all model parameters by scaling them inversely proportional to the square root of the sum of all of their historical squared values. The parameters that receive high gradients will have their effective learning rate reduced, while parameters that receive small or infrequent updates will have their effective learning rate increased. Amusingly, the square root operation turns out to be very important and without it the algorithm performs much worse.</p> \[\begin{aligned} \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_{\theta} \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{r} &amp;\leftarrow \boldsymbol{r} + \boldsymbol{g} \odot \boldsymbol{g} \\ \boldsymbol{\theta} &amp;\leftarrow \boldsymbol{\theta} - \frac{\epsilon}{\delta+\sqrt{\boldsymbol{r}}} \odot \boldsymbol{g} \end{aligned}\] <p>The main weakness is its accumulation of the squared gradients in the denominator: Since every added term is positive, the accumulated sum keeps growing during training. This in turn causes the learning rate to shrink and eventually become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge.</p> <h3 id="rmsprop">RMSProp</h3> <p>The RMSProp update adjusts the AdaGrad method in a very simple way in an attempt to reduce its aggressive, monotonically decreasing learning rate. In particular, it uses a exponentially moving average of squared gradients instead. The RMSProp still modulates the learning rate of each parameter based on the magnitudes of its gradients, which has a beneficial equalizing effect, but unlike AdaGrad the updates do not get monotonically smaller.</p> \[\begin{aligned} \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_{\theta} \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{r} &amp;\leftarrow \rho\boldsymbol{r} + (1-\rho)\boldsymbol{g} \odot \boldsymbol{g} \\ \boldsymbol{\theta} &amp;\leftarrow \boldsymbol{\theta}-\frac{\epsilon}{\sqrt{\delta+\boldsymbol{r}}}\odot \boldsymbol{g} \end{aligned}\] <h3 id="adam">Adam</h3> <p>The name “Adam” derives from the phrase “adaptive moments”. In addition to storing an exponentially decaying average of past squared gradients like RMSProp, Adam also keeps an exponentially decaying average of past gradients, similar to momentum. Furthermore, Adap includes bias corrections to the estimates of both the first-order moments and the second-order moments to account for their initialization at the origin.</p> \[\begin{aligned} \boldsymbol{g} &amp;\leftarrow \frac{1}{m} \nabla_{\theta} \sum_{i=1}^{m}L(f(x^{(i)};\boldsymbol{\theta}), y^{(i)}) \\ \boldsymbol{s} &amp;\leftarrow \rho_1\boldsymbol{s} + (1-\rho_1)\boldsymbol{g} \\ \boldsymbol{r} &amp;\leftarrow \rho_2\boldsymbol{r} + (1-\rho_2)\boldsymbol{g} \odot \boldsymbol{g} \\ \hat{s} &amp;\leftarrow \frac{\boldsymbol{s}}{1-\rho_1^t} \\ \hat{\boldsymbol{r}} &amp;\leftarrow \frac{\boldsymbol{r}}{1-\rho_2^t} \\ \boldsymbol{\theta} &amp;\leftarrow \boldsymbol{\theta}-\epsilon\frac{\hat{\boldsymbol{s}}}{\sqrt{\hat{\boldsymbol{r}}}+\delta} (operations applied element-wise) \end{aligned}\] <blockquote> <p>In practice Adam is currently recommended as the default algorithm to use, and often works slightly better than RMSProp. However, it is often also worth trying SGD+Nesterov Momentum as an alternative.</p> </blockquote> <h2 id="reference">Reference</h2> <ul> <li>Deep Learning Book</li> <li>https://cs231n.github.io/neural-networks-3/</li> <li>https://ruder.io/optimizing-gradient-descent/</li> <li>https://ocxs.gitbooks.io/deep-learning/content/cs231n/001_training_optimization.html</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Basic Algorithms Stochastic Gradient Descent (SGD) Stochastic gradient descent is an extension of the gradient descent algorithm. Instead of being computed on the entire training sets, the SGD is computed on one minibatch drawn uniformly from the training set. The insight behind this is that the gradient is an expectation and the expectation may be approximately estimated using a small set of samples.]]></summary></entry></feed>